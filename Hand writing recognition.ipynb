{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network and Machine Learning for Signal Processing Workshop for EST's internship 2018 \n",
    "\n",
    "Author : Suradej Dunapummet\n",
    "\n",
    "Advance Automation and Electronics Research Unit, NECTEC\n",
    "\n",
    "Created : June 13, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Lab 15 : Handwritten digit recognition \n",
    "Aims:\n",
    "\n",
    "1.How to develop and evaluate a simple neural network called Multilayer Perceptron, MLP.\n",
    "\n",
    "2.How to implement and evaluate a simple Convolutional Neural Network, CNN.\n",
    "##### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset\n",
    "The MNIST problem is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem.\n",
    "\n",
    "The dataset was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5kdETmLzIyIn/R+KxB3xQTzcVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22384781240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape and normalize the input from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32).reshape((x_train.shape[0],28*28))/255.0\n",
    "x_test = x_test.astype(np.float32).reshape((x_test.shape[0],28*28))/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a digit recognition task. As such there are 10 digits (0 to 9) or 10 classes to predict. We can use a one hot encoding of the class values, transforming the vector of class integers into a binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot vector looks like : [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"One hot vector looks like :\",y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the random number generator to a constant to ensure that the results of your script are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multilayer Perceptron, MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](mnistMLP.png)\n",
    "\n",
    "ref:http://corochann.com/mnist-training-with-multi-layer-perceptron-1149.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected feedforward network \n",
    "\n",
    "Hidden node = 100\n",
    "\n",
    "Activation function = sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense (1000, input_dim = 784, activation = 'sigmoid'))\n",
    "#mlp.add(Dense (500, input_dim = 784, activation = 'sigmoid'))\n",
    "mlp.add(Dense (10, activation='sigmoid'))\n",
    "mlp.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.3698 - acc: 0.8919\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.2065 - acc: 0.9393\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.1444 - acc: 0.9577\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1053 - acc: 0.9687\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.0818 - acc: 0.9759\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.0627 - acc: 0.9812\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.0504 - acc: 0.9846\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 23s 388us/step - loss: 0.0381 - acc: 0.9885\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.0302 - acc: 0.9913\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.0234 - acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2238f1f4e10>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Multilayer percepton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Error: 93.36%\n"
     ]
    }
   ],
   "source": [
    "score = mlp.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"MLP Error: %.2f%%\" % (100-score[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convolutional Neural Network, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](mnistCNN2.png)\n",
    "Ref: LeCun et al., 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32).reshape((x_train.shape[0],28,28,1))/255.0\n",
    "x_test = x_test.astype(np.float32).reshape((x_test.shape[0],28,28,1))/255.0\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import (Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 10)        90        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 7840)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                78410     \n",
      "=================================================================\n",
      "Total params: 78,500\n",
      "Trainable params: 78,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add( Conv2D (10, (3,3), padding='same', use_bias=False, data_format = 'channels_last', input_shape =(28,28,1)))\n",
    "#cnn.add( BatchNormalization(axis=-1))\n",
    "cnn.add( Activation('relu'))\n",
    "#cnn.add( MaxPooling2D(pool_size=(2,2),data_format='channels_last'))\n",
    "cnn.add(Flatten())\n",
    "cnn.add( Dense(10, activation='softmax'))\n",
    "cnn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.2879 - acc: 0.9205\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.1215 - acc: 0.9648\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.0824 - acc: 0.9766\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.0641 - acc: 0.9816\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 0.0535 - acc: 0.98431s - loss: 0.0\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0450 - acc: 0.9865\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.0395 - acc: 0.98810s - loss: 0.0396 - acc: 0.\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.0340 - acc: 0.9901\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0300 - acc: 0.9911\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.0263 - acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2238f29d358>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train, y_train,batch_size=batch_size, epochs=epochs, shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Error: 93.09%\n"
     ]
    }
   ],
   "source": [
    "score = cnn.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-score[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Larger Convolutional Neural Network\n",
    "\n",
    "\n",
    "We try to add more layers and more features on each layer, for example,\n",
    "\n",
    "Two Convolutional layers with 30 feature maps of size 5×5 and 15 feature maps of size 3×3\n",
    "\n",
    "Fully connected layer with 128 neurons and rectifier activation.\n",
    "\n",
    "Fully connected layer with 50 neurons and rectifier activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][pixels]\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 24, 24, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 15)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               48128     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 59,933\n",
      "Trainable params: 59,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "L_cnn = Sequential()\n",
    "L_cnn.add(Conv2D(30, (5, 5), input_shape=(28, 28,1), activation='relu'))\n",
    "L_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "L_cnn.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "L_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "L_cnn.add(Dropout(0.2))\n",
    "L_cnn.add(Flatten())\n",
    "L_cnn.add(Dense(128, activation='relu'))\n",
    "L_cnn.add(Dense(50, activation='relu'))\n",
    "L_cnn.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "L_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "L_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2429 - acc: 0.9239\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 58s 959us/step - loss: 0.0707 - acc: 0.9776\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 58s 967us/step - loss: 0.0547 - acc: 0.9828\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0469 - acc: 0.9850\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0391 - acc: 0.9874\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 60s 994us/step - loss: 0.0343 - acc: 0.9890\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.0308 - acc: 0.9899\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0271 - acc: 0.9914: 1s - loss: 0.\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0257 - acc: 0.9913\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0227 - acc: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2238a3b1898>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_cnn.fit(x_train, y_train,batch_size=batch_size, epochs=epochs, shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Larger CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large CNN Error: 97.49%\n"
     ]
    }
   ],
   "source": [
    "score = L_cnn.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
